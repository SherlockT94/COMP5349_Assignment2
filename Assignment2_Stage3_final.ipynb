{"cells": [{"metadata": {"trusted": false}, "cell_type": "code", "source": "import tensorflow as tf\nimport tensorflow_hub as hub\nimport numpy as np\nfrom pyspark.sql import SparkSession", "execution_count": 1, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "31a1c167c738494a84df5c5cdbbc6905"}}, "metadata": {}}, {"output_type": "stream", "text": "Starting Spark application\n", "name": "stdout"}, {"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.HTML object>", "text/html": "<table>\n<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>3</td><td>application_1558397948671_0004</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-16-213.us-east-2.compute.internal:20888/proxy/application_1558397948671_0004/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-27-94.us-east-2.compute.internal:8042/node/containerlogs/container_1558397948671_0004_01_000001/livy\">Link</a></td><td>\u2714</td></tr></table>"}, "metadata": {}}, {"output_type": "stream", "text": "SparkSession available as 'spark'.\n", "name": "stdout"}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "#New SparkSession\n#can not overwrite the configuration in cluster\nspark = SparkSession \\\n    .builder \\\n    .appName(\"Spark Text Encoder example\") \\\n    .getOrCreate()", "execution_count": 2, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "6b2859853fca49a8bf7664e5c018d558"}}, "metadata": {}}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "rev_data = \"s3://amazon-reviews-pds/tsv/amazon_reviews_us_Music_v1_00.tsv.gz\"\nrevs = spark.read.csv(rev_data,header=True,sep='\\t')", "execution_count": 3, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "b6c72cf5c9c844449a024d317e2b43cb"}}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "# Stage3 - 5.1 Postive vs. Negative Reviews\n## 1. Remove HTML tag"}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "# select one of the top10 product\nproductRecords = revs.filter(revs.product_id == 'B004EBT5CU')", "execution_count": 4, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "1a0475fae7494c4790ee1acf42cff520"}}, "metadata": {}}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "# select the column that matters \nrefinedProRec = productRecords.select(\"review_id\", \"review_body\", \"star_rating\")", "execution_count": 5, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "a372bcc825f84f7b888bae1db10f1b8c"}}, "metadata": {}}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "# remove the None review_body\nrNoneContent = refinedProRec.filter(refinedProRec.review_body != '')", "execution_count": 6, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "2015162eb9a245bdac5f9624be600919"}}, "metadata": {}}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "import re\nfrom pyspark.sql.functions import udf\nfrom pyspark.sql.types import ArrayType, StringType\nfrom pyspark.sql.functions import lit\nfrom pyspark.sql import functions as F\n\ndef filterout_htmltag(x):\n    tag_pattern = re.compile('<.*?>')\n    cleantag = re.sub(tag_pattern, ' ', x)\n    return cleantag\n\nclean_htmltag = udf(lambda x: filterout_htmltag(x), StringType())\n\nremoveHTag = rNoneContent.withColumn(\"review_body\", lit(clean_htmltag(rNoneContent['review_body'])))", "execution_count": 7, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "45cb080852e94924ace840e35519d26b"}}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "## 2. Split review_body"}, {"metadata": {}, "cell_type": "markdown", "source": "**In the next cell, I use regular expression to split review_body into sentences and use the udf(user defined function) to apply it to the dataframe**"}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "import re\nfrom pyspark.sql.functions import udf\nfrom pyspark.sql.types import ArrayType, StringType\n\npattern = re.compile(r'[\\.\\?\\!]+ ')\ndef segmentReview(x):\n    contentList = re.split(pattern, x)\n    return contentList\n\ncontentOfSen = udf(lambda x: segmentReview(x), ArrayType(StringType()))#set type is important!!!!!!!!!!", "execution_count": 11, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "d8153f7494824f7a9c159ea07804a891"}}, "metadata": {}}]}, {"metadata": {"scrolled": true, "trusted": false}, "cell_type": "code", "source": "#filter the star_rating greate than 4 and add a new column \"sentences\" to the dataframe\nposClass = removeHTag.filter(removeHTag.star_rating >= 4).withColumn(\"sentences\", contentOfSen(removeHTag.review_body)).cache()", "execution_count": 13, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "c7ed02a6c895428d8f7814aabc952818"}}, "metadata": {}}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "#explode the \"sentence\" column into the different rows\nfrom pyspark.sql.functions import split, explode\nsenPosClass = posClass.withColumn('sentence', explode(posClass.sentences))", "execution_count": 14, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "4be2649e7a9e48028174ee6ef3e774db"}}, "metadata": {}}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "#filter the star_rating less than 2 and add a new column \"sentences\" to the dataframe\nnegClass = removeHTag.filter(removeHTag.star_rating <= 2).withColumn(\"sentences\", contentOfSen(removeHTag.review_body)).cache()", "execution_count": 15, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "5fd33cdd8134482198a4d0e29a92d01c"}}, "metadata": {}}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "#explode the \"sentence\" column into the different rows\nsenNegClass = negClass.withColumn('sentence', explode(negClass.sentences))", "execution_count": 16, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "dba8888f3946421ab2d64461714b30b1"}}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "## 3. Google Pre-trained universal sentence encoder\nembedded with Google Pre-trained universal sen- tence encoder. The result is a 512 dimension vector.\n### Transfer DataFrame to RDD"}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "#row[5] is the sentence column\nposClassRdd = senPosClass.rdd.map(lambda row: str(row[4]))\nnegClassRdd = senNegClass.rdd.map(lambda row: str(row[4]))", "execution_count": 17, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "3d0e5412b3cd4d7fb7df659a6d6e8464"}}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "### Embed Universal-sentence-encoder"}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "# embed function using Google pre-defined universal-sentence-encoder transfer sentence into Vectors\ndef senEmbed(sen):\n    module_url = \"https://tfhub.dev/google/universal-sentence-encoder/2\" #@param [\"https://tfhub.dev/google/universal-sentence-encoder/2\", \"https://tfhub.dev/google/universal-sentence-encoder-large/3\"]\n    embed = hub.Module(module_url)\n    # mapPartition would supply element inside a partition using generator stype\n    # this does not fit tensorflow stype\n    # sen : a iterable object contains the elements in the rev_text_partition\n    # second loop is for the each sentence in the list\n    # create a list for all sentence\n    rev_text_list = [text for text in sen]\n    with tf.Session() as session:\n        session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n        message_embeddings = session.run(embed(rev_text_list))\n    return message_embeddings", "execution_count": 18, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "4a068ad03ecd48bbaf651e151765de6c"}}, "metadata": {}}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "#transfer the sentence of positive class & negitive class into vector\nposSentenceEmbedding = posClassRdd.mapPartitions(senEmbed).cache()\nnegSentenceEmbedding = negClassRdd.mapPartitions(senEmbed).cache()", "execution_count": 19, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "b93b654d4bee403880d6ea1771934ac2"}}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "# Stage3 - 5.2 Intra-Class Similarity\nWe want to find out if sentences in the same category are closely related with each other. The closeness is measured by average distance between points in the class. In our case, point refers to the sentence encoding and pair-wise distance is measured by Cosine distance. Cosine distance is computed as \u201c1 \u2212 CosineSimilarity\u201d. It has a value between 0 and 2."}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "# calculate the cosine similarity\ndef calCosine(vector1, vector2):\n    result = np.dot(vector1,vector2)\n    norm = np.linalg.norm(vector1)*np.linalg.norm(vector2)\n    cos = result/norm\n    return (1-cos)", "execution_count": 22, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "6a6edd89ffbf4118abdf9672b9d5a5df"}}, "metadata": {}}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "# calculate the average cosine similarity\ndef calAverage(list):\n    list2 = []\n    for x in list:\n        list1 = []\n        for y in list:\n            if ((x == y).all()) == False:\n                list1.append(calCosine(x, y))\n        average = sum(list1)/len(list1)\n        list2.append(average)\n    return list2", "execution_count": 23, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "49ae32a61e1946a8b9e9751e7eeb83df"}}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "## positive class"}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "embedLenPos = posSentenceEmbedding.count()", "execution_count": 24, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "76fcbd3377e54601ba4f4b941e08d2af"}}, "metadata": {}}, {"output_type": "stream", "text": "----------------------------------------\nException happened during processing of request from ('127.0.0.1', 45446)\nTraceback (most recent call last):\n  File \"/usr/lib64/python3.6/socketserver.py\", line 320, in _handle_request_noblock\n    self.process_request(request, client_address)\n  File \"/usr/lib64/python3.6/socketserver.py\", line 351, in process_request\n    self.finish_request(request, client_address)\n  File \"/usr/lib64/python3.6/socketserver.py\", line 364, in finish_request\n    self.RequestHandlerClass(request, client_address, self)\n  File \"/usr/lib64/python3.6/socketserver.py\", line 724, in __init__\n    self.handle()\n  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/accumulators.py\", line 266, in handle\n    poll(authenticate_and_accum_updates)\n  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/accumulators.py\", line 241, in poll\n    if func():\n  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/accumulators.py\", line 254, in authenticate_and_accum_updates\n    received_token = self.rfile.read(len(auth_token))\nTypeError: object of type 'NoneType' has no len()\n----------------------------------------", "name": "stdout"}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "#transfer RDD to a list of Vecters\nposSentenceEmbeddingVectors = posSentenceEmbedding.take(embedLenPos)", "execution_count": 31, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "4ef3db1ee56f421eb352b2ee5933ce66"}}, "metadata": {}}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "#calculate the average dictance of every point\naverListPos = calAverage(posSentenceEmbeddingVectors)", "execution_count": null, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "80732376af794b4a9dceba962582c4d2"}}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "### find back records\n* using monotonically_increasing_id() to generate consecutive sentenceID, which is used to find back the record related to the point.\n* Create a list contains sentenceID \n* Create a dictionary, key: average distance for each point, value: sentenceID"}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "from pyspark.sql.functions import monotonically_increasing_id\nsenIDPos = senPosClass.withColumn(\"sentenceID\", monotonically_increasing_id())\nsenIDListPos = [x for x in range(senIDPos.count())]\ndicPos = dict(map(lambda x,y:[x,y],averListPos, senIDListPos))", "execution_count": 33, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "4e9c71f83cf94382ad75d39241fce39c"}}, "metadata": {}}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "minAveragePos = min(averListPos)\nminSenIDPos = dicPos[minAveragePos]\nprint(minSenIDPos)", "execution_count": 34, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "987c6c76000a452983254313008e3f55"}}, "metadata": {}}, {"output_type": "stream", "text": "3240", "name": "stdout"}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "#output the center\noutputListPos = senIDPos.filter(senIDPos.sentenceID == minSenIDPos).select(\"review_id\", \"sentence\").collect()", "execution_count": 35, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "bb64c96cbb7247c79c66f76c5ef74576"}}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "**Find the Top10 Neighbor:**\n1. vRDD - the rdd contains vectors\n2. sID - the sentenceID of center\n3. length - the length of RDD"}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "#recalculate the cosine distance and put every distance into a dictionary as the key. The value is the sentenceID\ndef findTen(vRDD, sID, length):\n    vList = vRDD.take(length) # list of vector\n    dList = [] #list of cosine distance\n    dic = {} \n    i = 0 # dictionary value\n    tList =[] # top10 list\n    for x in vList:\n        if ((x == vList[sID]).all()) == False:\n            cosine = calCosine(x, vList[sID])\n            dList.append(cosine)\n            dic[cosine] = i\n            i += 1\n    dList.sort() # sort the distance list\n    for cos in dList[:10]:\n        tList.append(dic[cos])\n    return tList", "execution_count": 36, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "5a984c91be6d4894bf753b79b1d21097"}}, "metadata": {}}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "listIDPos = findTen(posSentenceEmbedding, minSenIDPos, embedLenPos)", "execution_count": 37, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "534a5505a4b24f679660a96945a76a6a"}}, "metadata": {}}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "for i in listIDPos:\n    tempListPos = []\n    tempListPos = senIDPos.filter(senIDPos.sentenceID == i).select(\"review_id\", \"sentence\").collect()\n    outputListPos.append(tempListPos[0])", "execution_count": 39, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "94c40af9bc1040c593414e55ab16f31f"}}, "metadata": {}}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "count = 0\nfor i in outputListPos:\n    if count == 0:\n        print('Center Sentence:')\n        print('review_id: ' + i.review_id)\n        print('content of sentence: ' + i.sentence)\n        print('----------------------------------------------------------------------------')\n        print('Top 10  Neighbor:')\n        count += 1\n    else:\n        print('review_id: ' + i.review_id)\n        print('content of sentence: ' + i.sentence)\n        print()", "execution_count": 40, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "01b7effd00954d0a8c9850c09d29743b"}}, "metadata": {}}, {"output_type": "stream", "text": "Center Sentence:\nreview_id: R3SBLDHLGWU3CQ\ncontent of sentence: I love Adele and this CD is fantastic\n----------------------------------------------------------------------------\nTop 10  Neighbor:\nreview_id: R3LNZ080XD5U72\ncontent of sentence: I love Adele and this CD is just wonderful\n\nreview_id: R1A4J1EM06YPN2\ncontent of sentence:  For fun, watch the SNL skit with Emma Stone as Adele's song is the topic.\n\nreview_id: R1ZCPBTGSZGCOB\ncontent of sentence: Just buy it !\n\nreview_id: R3KAX2RX0I8QC4\ncontent of sentence: I love this cd and I love all of the music on it if you like Adele get this CD.!!!!\n\nreview_id: R3QSLNGLJ04CTH\ncontent of sentence: Great Singer-singing w/ thought provoking lyrics.\n\nreview_id: R7PWW0ZRAZ4EN\ncontent of sentence: I love this CD because I think Adele is perfect\n\nreview_id: RTDKHB1K5H1NB\ncontent of sentence: Love this CD from Adele - ALL the songs are great\n\nreview_id: RMIJKZJ4ZAYKB\ncontent of sentence: I love Adele and was not disappointed with this CD\n\nreview_id: R2B2110OCFBK5E\ncontent of sentence: I love this CD even more than Adele 19\n\nreview_id: R10M6CPCRUV7AW\ncontent of sentence: I love this cd, it has alot of Adele greatest hits", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "## negitive class"}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "embedLenNeg = negSentenceEmbedding.count()\nnegSentenceEmbeddingList = negSentenceEmbedding.take(embedLenNeg)\naverListNeg = calAverage(negSentenceEmbeddingList)", "execution_count": 41, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "8332ff845f2448f4bdc38a2145be885d"}}, "metadata": {}}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "print(embedLenNeg)", "execution_count": 42, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "cde7e8497304472ea7f22d2ef3f9c043"}}, "metadata": {}}, {"output_type": "stream", "text": "455", "name": "stdout"}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "senIDNeg = senNegClass.withColumn(\"sentenceID\", monotonically_increasing_id())\nsenIDListNeg = [x for x in range(senIDNeg.count())]\ndicNeg = dict(map(lambda x,y:[x,y],averListNeg, senIDListNeg))\nminAverageNeg = min(averListNeg)\nminSenIDNeg = dicNeg[minAverageNeg]", "execution_count": 43, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "b643d279f274448194e74ae79a09df86"}}, "metadata": {}}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "outputListNeg = senIDNeg.filter(senIDNeg.sentenceID == minSenIDNeg).select(\"review_id\", \"sentence\").collect()", "execution_count": 44, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "83b471da52184e47a12b3def263bc2eb"}}, "metadata": {}}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "listIDNeg = findTen(negSentenceEmbedding, minSenIDNeg, embedLenNeg)", "execution_count": 45, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "7b0aab12d130424ab5aecc3dda423ce3"}}, "metadata": {}}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "for i in listIDNeg:\n    tempListPos = []\n    tempListPos = senIDNeg.filter(senIDNeg.sentenceID == i).select(\"review_id\", \"sentence\").collect()\n    outputListNeg.append(tempListPos[0])", "execution_count": 46, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "c2f6a5aff3c34fb2878a31309aef950c"}}, "metadata": {}}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "count = 0\nfor i in outputListNeg:\n    if count == 0:\n        print('Center Sentence:')\n        print('review_id: ' + i.review_id)\n        print('content of sentence: ' + i.sentence)\n        print('----------------------------------------------------------------------------')\n        print('Top 10  Neighbor:')\n        count += 1\n    else:\n        print('review_id: ' + i.review_id)\n        print('content of sentence: ' + i.sentence)\n        print()", "execution_count": 47, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "b06e48370f694e808cd3b83985cce2ea"}}, "metadata": {}}, {"output_type": "stream", "text": "Center Sentence:\nreview_id: R14GO9494QD0UP\ncontent of sentence: Adele's music has it all\n----------------------------------------------------------------------------\nTop 10  Neighbor:\nreview_id: R13TD1FE6KGHTY\ncontent of sentence: Adele has the pipes, but the music is VERY derivative\n\nreview_id: RAV33939RLHCF\ncontent of sentence:  I am a frequent Amazon shopper and this is the first time I have had any issues, but I am bummed that I have to give this as a gift.\n\nreview_id: R26FGK6YKP8C9H\ncontent of sentence:  For those of us who remember the truly great performers, Adele is really average\n\nreview_id: R17HRZ4TJ0A8BX\ncontent of sentence: PLEASE LISTEN TO THE BRITISH SINGER \\\\\"RUMER\\\\\" TO UNDERSTAND THE DIFFERENCE BETWEEN SINGING AND SHOUTING\n\nreview_id: R31NJOJB47HYS4\ncontent of sentence: I must be in the minority-- I couldn't get to this album, or the artist either\n\nreview_id: R3BYX4UBOFLKQO\ncontent of sentence: You want good music\n\nreview_id: RCYY788RCLY3E\ncontent of sentence: Sorry if this offends anyone, but the first song I heard from Adele was Rolling in the Deep\n\nreview_id: RZO0HIT57VY1M\ncontent of sentence:  I will get my soul elsewhere.\n\nreview_id: R3BYX4UBOFLKQO\ncontent of sentence: Adele is trying too hard on this album\n\nreview_id: R3BYX4UBOFLKQO\ncontent of sentence: All Adele is, and I don't care what YOU think (Ohhhoho", "name": "stdout"}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "pysparkkernel", "display_name": "PySpark", "language": ""}, "language_info": {"name": "pyspark", "mimetype": "text/x-python", "codemirror_mode": {"name": "python", "version": 2}, "pygments_lexer": "python2"}}, "nbformat": 4, "nbformat_minor": 2}